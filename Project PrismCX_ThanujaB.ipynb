{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d69a62f0-5fb4-4d7c-8ba5-02f2f87c5310",
   "metadata": {},
   "source": [
    "#  Project PrismCX – Emphasizing customer experience and segmentation across many dimensions.\n",
    "\n",
    "### 📌 Objective\n",
    "To develop a data-driven customer segmentation model for an IoT-based home automation company by leveraging RFM (Recency, Frequency, Monetary) analysis and the CORE (Convert, Optimize, Retain, Exit) strategy to improve customer engagement, retention, and marketing personalization.\n",
    "- **Convert** – New or low-engagement customers\n",
    "- **Optimize** – Recently active but moderate value\n",
    "- **Retain** – Loyal and high-value customers\n",
    "- **Exit** – Lapsed or at-risk customers\n",
    "\n",
    "---\n",
    "\n",
    "### 🧾 Dataset Description\n",
    "The dataset used (`SmartHome_PrismCX_Segmentation.csv`) contains 50,000 transaction records with:\n",
    "- Customer ID, Transaction Date, Transaction Value\n",
    "- Product Category, Payment Method, Gender, Age Group, Region\n",
    "\n",
    "---\n",
    "\n",
    "### 🛠 Tools Used\n",
    "- Python (Pandas, Datetime)\n",
    "- Exported CSV for Tableau Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219ed626-0e99-464e-95b9-e51e1903f24a",
   "metadata": {},
   "source": [
    "## Step 1: Load Transaction Data\n",
    "We load the UrbanMart dataset and convert `TransactionDate` to datetime format so we can later compute recency. We also define a snapshot date as one day after the last transaction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eddce2de-4964-4976-9c48-a067a4ed45d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3818ef5-2059-4789-aafc-c62c7541b615",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'SmartHome_PrismCX_Segmentation.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSmartHome_PrismCX_Segmentation.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39minfo())\n",
      "File \u001b[1;32m~\\Downloads\\Telegram Desktop\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\Downloads\\Telegram Desktop\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\Downloads\\Telegram Desktop\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\Downloads\\Telegram Desktop\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\Downloads\\Telegram Desktop\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'SmartHome_PrismCX_Segmentation.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"SmartHome_PrismCX_Segmentation.csv\")\n",
    "print(df.shape)\n",
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1588,
   "id": "4ac13e40-2a58-4d1a-a806-bffc6c489c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(thresh=df.shape[1] - 2)\n",
    "\n",
    "# Fill numerical columns with mean\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "\n",
    "# Fill categorical columns with mode\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1590,
   "id": "4bd50f8a-0dc0-4218-98cc-053394337f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'], errors='coerce')\n",
    "df = df.dropna(subset=['TransactionDate'])\n",
    "snapshot_date = df['TransactionDate'].max() + timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa38f53a-09d7-415c-9306-ef3b630b518d",
   "metadata": {},
   "source": [
    "## Step 2: Calculate RFM Metrics\n",
    "We calculate:\n",
    "- **Recency**: Days since last purchase\n",
    "- **Frequency**: Number of purchases\n",
    "- **Monetary**: Total spending\n",
    "\n",
    "This is done by grouping data by `CustomerID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1593,
   "id": "85e09f9f-6e0a-4a3e-b43d-d00b1a1eed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm = df.groupby('CustomerID').agg({\n",
    "    'TransactionDate': lambda x: (snapshot_date - x.max()).days,  # Recency\n",
    "    'TransactionID': 'count',                                     # Frequency\n",
    "    'TransactionValue': ['sum', 'mean']                           # Monetary + Avg Value\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1595,
   "id": "e73b66f4-7e56-49a6-b080-d35ad5ed7efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten MultiIndex columns\n",
    "rfm.columns = ['CustomerID', 'Recency', 'TransactionCount', 'Monetary', 'AvgTransactionValue']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afe44a3-b029-4a96-941f-b736bf9f9d39",
   "metadata": {},
   "source": [
    "## Step 3: Analyze RFM Distribution\n",
    "We print descriptive statistics and percentiles for Recency, Frequency, and Monetary. These values help us determine thresholds for churn risk, loyalty, and top spenders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1598,
   "id": "d3652a98-5735-4c5a-b17b-0bfa659ebf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 ===== Recency (days since last purchase) =====\n",
      "count    2000.000000\n",
      "mean       29.610000\n",
      "std        28.727975\n",
      "min         1.000000\n",
      "25%         9.000000\n",
      "50%        20.000000\n",
      "75%        42.000000\n",
      "max       215.000000\n",
      "Name: Recency, dtype: float64\n",
      "\n",
      "🔂 ===== Frequency (number of purchases) =====\n",
      "count    2000.000000\n",
      "mean       25.000000\n",
      "std         5.057152\n",
      "min        11.000000\n",
      "25%        21.000000\n",
      "50%        25.000000\n",
      "75%        28.000000\n",
      "max        45.000000\n",
      "Name: TransactionCount, dtype: float64\n",
      "\n",
      "💸 ===== Monetary (total spending) =====\n",
      "count    2.000000e+03\n",
      "mean     6.335203e+07\n",
      "std      1.468154e+07\n",
      "min      1.909434e+07\n",
      "25%      5.328737e+07\n",
      "50%      6.268898e+07\n",
      "75%      7.276311e+07\n",
      "max      1.147111e+08\n",
      "Name: Monetary, dtype: float64\n",
      "\n",
      "🎯 ===== Key Percentiles =====\n",
      "\n",
      "📊 Recency percentiles:\n",
      "0.25     9.0\n",
      "0.50    20.0\n",
      "0.75    42.0\n",
      "0.90    68.0\n",
      "0.95    85.0\n",
      "Name: Recency, dtype: float64\n",
      "\n",
      "📊 TransactionCount percentiles:\n",
      "0.25    21.0\n",
      "0.50    25.0\n",
      "0.75    28.0\n",
      "0.90    32.0\n",
      "0.95    34.0\n",
      "Name: TransactionCount, dtype: float64\n",
      "\n",
      "📊 Monetary percentiles:\n",
      "0.25    53287368.25\n",
      "0.50    62688983.50\n",
      "0.75    72763112.00\n",
      "0.90    83269812.60\n",
      "0.95    88675561.05\n",
      "Name: Monetary, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Add emojis, lines, and spacing for readability\n",
    "print(\"🔁 ===== Recency (days since last purchase) =====\")\n",
    "print(rfm['Recency'].describe())\n",
    "\n",
    "print(\"\\n🔂 ===== Frequency (number of purchases) =====\")\n",
    "print(rfm['TransactionCount'].describe())\n",
    "\n",
    "print(\"\\n💸 ===== Monetary (total spending) =====\")\n",
    "print(rfm['Monetary'].describe())\n",
    "\n",
    "# Print percentiles\n",
    "print(\"\\n🎯 ===== Key Percentiles =====\")\n",
    "for metric in ['Recency', 'TransactionCount', 'Monetary']:\n",
    "    print(f\"\\n📊 {metric} percentiles:\")\n",
    "    print(rfm[metric].quantile([0.25, 0.5, 0.75, 0.9, 0.95]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4f59c7-2d42-44e4-a545-c10014d13abf",
   "metadata": {},
   "source": [
    "## Step X: Automated RFM Scoring Based on Data Quantiles\n",
    "\n",
    "Instead of hardcoding or manually assigning RFM scores using `qcut`, we automate scoring using the dataset's actual distribution.  \n",
    "We calculate the 25th, 50th, and 75th percentiles for Recency, Frequency, and Monetary, then assign scores:\n",
    "\n",
    "- **Score 4** = Best performers\n",
    "- **Score 1** = Least engaged\n",
    "\n",
    "For **Recency**, lower is better (recent shoppers), so scoring is reversed:\n",
    "- Recency ≤ 25th percentile → Score 4\n",
    "- Recency > 75th percentile → Score 1\n",
    "\n",
    "For **Frequency** and **Monetary**, higher is better:\n",
    "- Frequency ≥ 75th percentile → Score 4\n",
    "- Frequency ≤ 25th percentile → Score 1\n",
    "\n",
    "This makes the scoring system **adaptive to any dataset** and removes reliance on `qcut`, which can break with outliers or skewed data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1601,
   "id": "952e39e5-9fe7-439d-82d4-82e4c3592674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_rfm(value, quantiles, reverse=False):\n",
    "   \n",
    "    if value <= quantiles[0.25]:\n",
    "        return 4 if reverse else 1\n",
    "    elif value <= quantiles[0.50]:\n",
    "        return 3 if reverse else 2\n",
    "    elif value <= quantiles[0.75]:\n",
    "        return 2 if reverse else 3\n",
    "    else:\n",
    "        return 1 if reverse else 4\n",
    "\n",
    "\n",
    "r_quartiles = rfm['Recency'].quantile([0.25, 0.50, 0.75])\n",
    "f_quartiles = rfm['TransactionCount'].quantile([0.25, 0.50, 0.75])\n",
    "m_quartiles = rfm['Monetary'].quantile([0.25, 0.50, 0.75])\n",
    "\n",
    "\n",
    "rfm['R_Score'] = rfm['Recency'].apply(score_rfm, args=(r_quartiles, True))\n",
    "rfm['F_Score'] = rfm['TransactionCount'].apply(score_rfm, args=(f_quartiles, False))\n",
    "rfm['M_Score'] = rfm['Monetary'].apply(score_rfm, args=(m_quartiles, False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4e5c09-1c75-492b-a040-a5975ac0c2c6",
   "metadata": {},
   "source": [
    "## Step 5: Map RFM Scores to CORE Segments\n",
    "We define a custom segmentation framework called **CORE**:\n",
    "- **Retain**: High R, F, and M scores (3+)\n",
    "- **Optimize**: Recent but not top-tier customers (R ≥ 3 with F or M = 2)\n",
    "- **Convert**: Mid Recency and low Frequency & Monetary\n",
    "- **Exit**: Everyone else, especially low Recency\n",
    "\n",
    "This logic helps businesses target marketing efforts strategically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1604,
   "id": "3278e00a-0d1d-4561-ac10-5f13ecbe1ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_core(r, f, m):\n",
    "    if r >= 3 and f >= 3 and m >= 3:\n",
    "        return 'Retain'\n",
    "    elif r >= 3 and (f == 2 or m == 2):\n",
    "        return 'Optimize'\n",
    "    elif r == 2 and f <= 2 and m <= 2:\n",
    "        return 'Convert'\n",
    "    else:\n",
    "        return 'Exit'\n",
    "\n",
    "rfm['CORE_Segment'] = rfm.apply(lambda row: classify_core(row['R_Score'], row['F_Score'], row['M_Score']), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d8f21f-0bf6-4daf-9347-bd20f3e603a9",
   "metadata": {},
   "source": [
    "## Step 6: Add Customer Flags\n",
    "We add important behavioral tags:\n",
    "- **Churn_Risk**: Recency > 90 days\n",
    "- **Top_Spender**: Top 10% in Monetary value\n",
    "- **IsLoyalCustomer**: Customers with 5 or more transactions\n",
    "\n",
    "These help further classify customers beyond RFM alone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1607,
   "id": "7cb9710b-3327-498c-a6e6-d98d62235560",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm['Churn_Risk'] = rfm['Recency'].apply(lambda x: 'Yes' if x > 90 else 'No')\n",
    "\n",
    "top_spend_threshold = rfm['Monetary'].quantile(0.90)\n",
    "rfm['Top_Spender'] = rfm['Monetary'].apply(lambda x: 'Yes' if x >= top_spend_threshold else 'No')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0632d34c-ea98-4aa0-a56f-163700d44a9f",
   "metadata": {},
   "source": [
    "## Step 7: Average Days Between Purchases\n",
    "This metric helps us understand how frequently a customer shops on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1610,
   "id": "2cbb2c3d-679d-48f2-8347-ffe56fd3ce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_intervals = df.sort_values(by=['CustomerID', 'TransactionDate']).groupby('CustomerID')['TransactionDate'].diff().dt.days\n",
    "avg_days_between = purchase_intervals.groupby(df['CustomerID']).mean().reset_index()\n",
    "avg_days_between.columns = ['CustomerID', 'AvgDaysBetweenPurchases']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cd2d6e-7cd8-4547-b8e2-b756c269b7fa",
   "metadata": {},
   "source": [
    "## Step 8: To determine if a custmer is a loyal customer or not\n",
    "This metric helps us understand if the customer is a regular or not by define the number of purchases to exceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1613,
   "id": "989e278c-9a36-4071-a52d-6ec3e132dfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm['IsLoyalCustomer'] = rfm['TransactionCount'].apply(lambda x: 'Yes' if x >= 5 else 'No')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edf2be7-f5f7-4d94-9b74-2a72ff13d7e3",
   "metadata": {},
   "source": [
    "## Step 9: Merge All Features and Export Final Dataset\n",
    "We merge the RFM + CORE + behavior flags back into the full transaction-level data and export it as a CSV to be used in Tableau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1616,
   "id": "8a37a517-e0af-4372-8a5c-c34fe04ae17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df, rfm, on='CustomerID', how='left')\n",
    "df_final.to_csv(\"UrbanMart_CORE_Segmentation_Enhanced.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1618,
   "id": "902fdc05-2246-4edb-b5f5-dc02303c32de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TransactionID CustomerID TransactionDate  TransactionValue ProductCategory  \\\n",
      "0   TRANS000000  CUST01574      2023-04-09            467907           Sport   \n",
      "1   TRANS000001  CUST01836      2024-08-05           2713789          Beauty   \n",
      "2   TRANS000002  CUST01291      2024-04-07           4539248         Fashion   \n",
      "3   TRANS000003  CUST00245      2024-06-12           3058426            Home   \n",
      "4   TRANS000004  CUST00163      2023-12-18           3304874         Fashion   \n",
      "5   TRANS000005  CUST00331      2024-11-24           1556151     Electronics   \n",
      "6   TRANS000006  CUST01956      2023-03-10           1664460            Home   \n",
      "7   TRANS000007  CUST01713      2023-04-10           4194384         Fashion   \n",
      "8   TRANS000008  CUST00112      2024-09-03           1184496           Sport   \n",
      "9   TRANS000009  CUST01726      2024-06-09           3314052            Home   \n",
      "\n",
      "   PaymentMethod CustomerGender CustomerAgeGroup    Region  Recency  \\\n",
      "0  Bank Transfer         Female              >50  Surabaya       23   \n",
      "1    Credit Card         Female            26-35  Surabaya       13   \n",
      "2  Bank Transfer           Male            18-25   Bandung       20   \n",
      "3  Bank Transfer           Male            36-50   Jakarta       33   \n",
      "4  Bank Transfer         Female            26-35   Jakarta       23   \n",
      "5    Credit Card           Male            18-25   Bandung       13   \n",
      "6       E-Wallet         Female            36-50   Jakarta       14   \n",
      "7    Credit Card         Female            36-50     Medan       52   \n",
      "8  Bank Transfer           Male            18-25  Surabaya       23   \n",
      "9       E-Wallet           Male              >50     Medan       39   \n",
      "\n",
      "   TransactionCount  Monetary  AvgTransactionValue  R_Score  F_Score  M_Score  \\\n",
      "0                37  86639269         2.341602e+06        2        4        4   \n",
      "1                27  79131352         2.930791e+06        3        3        4   \n",
      "2                26  71629418         2.754978e+06        3        3        3   \n",
      "3                20  57305316         2.865266e+06        2        1        2   \n",
      "4                22  43446375         1.974835e+06        2        2        1   \n",
      "5                21  48577055         2.313193e+06        3        1        1   \n",
      "6                19  56541036         2.975844e+06        3        1        2   \n",
      "7                23  62192915         2.704040e+06        1        2        2   \n",
      "8                21  46677992         2.222762e+06        2        1        1   \n",
      "9                31  78451900         2.530706e+06        2        4        4   \n",
      "\n",
      "  CORE_Segment Churn_Risk Top_Spender IsLoyalCustomer  \n",
      "0         Exit         No         Yes             Yes  \n",
      "1       Retain         No          No             Yes  \n",
      "2       Retain         No          No             Yes  \n",
      "3      Convert         No          No             Yes  \n",
      "4      Convert         No          No             Yes  \n",
      "5         Exit         No          No             Yes  \n",
      "6     Optimize         No          No             Yes  \n",
      "7         Exit         No          No             Yes  \n",
      "8      Convert         No          No             Yes  \n",
      "9         Exit         No          No             Yes  \n"
     ]
    }
   ],
   "source": [
    "print(df_final.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
